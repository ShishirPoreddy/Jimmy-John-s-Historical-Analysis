{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb727eab-4ec7-4693-87bc-f2c91bd15ed9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#part 1 Code\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m \n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m \n\u001b[1;32m      5\u001b[0m filename \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/Users/shishirporeddy/ECON433/weekly_patterns_2018_sample.csv.gz\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/Users/shishirporeddy/ECON433/weekly_patterns_2019_sample.csv.gz\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/Users/shishirporeddy/ECON433/weekly_patterns_2022_sample.csv.gz\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     11\u001b[0m ]\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/__init__.py:22\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m _hard_dependencies, _dependency, _missing_dependencies\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# numpy compat\u001b[39;00m\n\u001b[0;32m---> 22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m is_numpy_dev \u001b[38;5;28;01mas\u001b[39;00m _is_numpy_dev  \u001b[38;5;66;03m# pyright: ignore # noqa:F401\u001b[39;00m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_libs\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m hashtable \u001b[38;5;28;01mas\u001b[39;00m _hashtable, lib \u001b[38;5;28;01mas\u001b[39;00m _lib, tslib \u001b[38;5;28;01mas\u001b[39;00m _tslib\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/compat/__init__.py:25\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_constants\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     18\u001b[0m     IS64,\n\u001b[1;32m     19\u001b[0m     PY39,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     22\u001b[0m     PYPY,\n\u001b[1;32m     23\u001b[0m )\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompressors\u001b[39;00m\n\u001b[0;32m---> 25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     26\u001b[0m     is_numpy_dev,\n\u001b[1;32m     27\u001b[0m     np_version_under1p21,\n\u001b[1;32m     28\u001b[0m )\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyarrow\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     30\u001b[0m     pa_version_under7p0,\n\u001b[1;32m     31\u001b[0m     pa_version_under8p0,\n\u001b[1;32m     32\u001b[0m     pa_version_under9p0,\n\u001b[1;32m     33\u001b[0m     pa_version_under11p0,\n\u001b[1;32m     34\u001b[0m )\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mset_function_name\u001b[39m(f: F, name: \u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mcls\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m F:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/compat/numpy/__init__.py:4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\" support numpy compatibility across versions \"\"\"\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mversion\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Version\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# numpy versioning\u001b[39;00m\n\u001b[1;32m      7\u001b[0m _np_version \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39m__version__\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/util/__init__.py:2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# pyright: reportUnusedImport = false\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_decorators\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (  \u001b[38;5;66;03m# noqa:F401\u001b[39;00m\n\u001b[1;32m      3\u001b[0m     Appender,\n\u001b[1;32m      4\u001b[0m     Substitution,\n\u001b[1;32m      5\u001b[0m     cache_readonly,\n\u001b[1;32m      6\u001b[0m )\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhashing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (  \u001b[38;5;66;03m# noqa:F401\u001b[39;00m\n\u001b[1;32m      9\u001b[0m     hash_array,\n\u001b[1;32m     10\u001b[0m     hash_pandas_object,\n\u001b[1;32m     11\u001b[0m )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/util/_decorators.py:14\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m      7\u001b[0m     Any,\n\u001b[1;32m      8\u001b[0m     Callable,\n\u001b[1;32m      9\u001b[0m     Mapping,\n\u001b[1;32m     10\u001b[0m     cast,\n\u001b[1;32m     11\u001b[0m )\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mwarnings\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_libs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mproperties\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m cache_readonly\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_typing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     16\u001b[0m     F,\n\u001b[1;32m     17\u001b[0m     T,\n\u001b[1;32m     18\u001b[0m )\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_exceptions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m find_stack_level\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/_libs/__init__.py:13\u001b[0m\n\u001b[1;32m      1\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNaT\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNaTType\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInterval\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     10\u001b[0m ]\n\u001b[0;32m---> 13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_libs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minterval\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Interval\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_libs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtslibs\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     15\u001b[0m     NaT,\n\u001b[1;32m     16\u001b[0m     NaTType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     21\u001b[0m     iNaT,\n\u001b[1;32m     22\u001b[0m )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/_libs/interval.pyx:1\u001b[0m, in \u001b[0;36minit pandas._libs.interval\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject"
     ]
    }
   ],
   "source": [
    "#part 1 Code\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "\n",
    "filename = [\n",
    "    '/Users/shishirporeddy/ECON433/weekly_patterns_2018_sample.csv.gz',\n",
    "    '/Users/shishirporeddy/ECON433/weekly_patterns_2019_sample.csv.gz',\n",
    "    '/Users/shishirporeddy/ECON433/weekly_patterns_2020_sample.csv.gz',\n",
    "    '/Users/shishirporeddy/ECON433/weekly_patterns_2021_sample.csv.gz',\n",
    "    '/Users/shishirporeddy/ECON433/weekly_patterns_2022_sample.csv.gz'\n",
    "]\n",
    "row_dictionary={}\n",
    "core_qualification = 15 \n",
    "jj_list = []\n",
    "\n",
    "for file in filename:\n",
    "    datax = pd.read_csv(file, compression='gzip', low_memory= False)\n",
    "    row_dictionary[file] = len(datax)\n",
    "    print(datax.columns)\n",
    "    jj_data = datax[datax['brands'] ==\"Jimmy John's\"]\n",
    "    jj_list.append(jj_data)\n",
    "    \n",
    "\n",
    "concat_jj_data = pd.concat(jj_list, ignore_index=True)\n",
    "\n",
    "import datetime\n",
    "concat_jj_data['date_range_start'] = pd.to_datetime(concat_jj_data['date_range_start'], utc=True).dt.tz_localize(None)\n",
    "concat_jj_data['date_range_end'] = pd.to_datetime(concat_jj_data['date_range_end'], utc=True).dt.tz_localize(None)\n",
    "\n",
    "concat_jj_data[['dailyvisits1','dailyvisits2', 'dailyvisits3', \n",
    "                'dailyvisits4', 'dailyvisits5','dailyvisits6', \n",
    "                'dailyvisits7']] = concat_jj_data['visits_by_day'].str.strip(\"[]\").str.split(\",\", expand=True).apply(pd.to_numeric, \n",
    "                                                                                                                     errors='coerce')\n",
    "\n",
    "jj_long = concat_jj_data.melt(\n",
    "    id_vars=['placekey', 'date_range_start', 'date_range_end', 'region', 'brands', 'city', 'raw_visit_counts', 'visits_by_day'],\n",
    "    value_vars=['dailyvisits1','dailyvisits2', 'dailyvisits3', 'dailyvisits4', 'dailyvisits5', 'dailyvisits6', 'dailyvisits7'],\n",
    "    var_name='visits_column',\n",
    "    value_name='dailyvisits')\n",
    "\n",
    "\n",
    "jj_long[\"day_index\"] = (\n",
    "    jj_long[\"visits_column\"].str.extract(r'(\\d+)$') \n",
    "                   .astype(int)\n",
    ")\n",
    "jj_long[\"true_date\"] = jj_long[\"date_range_start\"] + pd.to_timedelta(jj_long[\"day_index\"] - 1, unit=\"D\")\n",
    "jj_long[\"dayofweek\"] = jj_long[\"true_date\"].dt.day_name()\n",
    "jj_long['dailyvisits'] = pd.to_numeric(jj_long['dailyvisits'], errors='coerce').fillna(0).astype(int)\n",
    "jj_long['WKND'] = jj_long['dayofweek'].isin(['Saturday', 'Sunday'])\n",
    "jj_long['threshold'] = np.where(jj_long['WKND'], 13, 18)\n",
    "jj_long['manyvisits'] = np.where(jj_long['dailyvisits'] > jj_long['threshold'], 1, 0)\n",
    "\n",
    "unique_in_region = (\n",
    "    jj_long.groupby('region', as_index=False)['placekey'].nunique().rename(columns={'placekey':'number_of_stores'}))\n",
    "\n",
    "jj_long = jj_long.merge(unique_in_region, on = 'region', how='left')\n",
    "jj_long['core_biz_area'] = np.where(jj_long['number_of_stores'] >= core_qualification, 1, 0)\n",
    "\n",
    "jj_long.to_csv(\"jimmy_johns_long_sample.csv\", index=False)\n",
    "\n",
    "\n",
    "print(jj_long.shape)\n",
    "print(jj_long.head(5))\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b64cdbd6-4f10-4311-bf04-9e25176d310e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#part 1 code\n",
    "unique_days = jj_long[\"dayofweek\"].unique()\n",
    "print(\"Unique values in day_of_week:\", unique_days)\n",
    "\n",
    "\n",
    "weekend_total = (jj_long['WKND'] == 1).sum()\n",
    "weekday_total = (jj_long['WKND'] == 0).sum()\n",
    "\n",
    "print(\"weekend total: \", weekend_total)\n",
    "print(\"weekday total: \", weekday_total)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "516f543a-ac82-4bec-8800-6063e38fd756",
   "metadata": {
    "tags": []
   },
   "source": [
    "Question 1:\n",
    "\n",
    "The unique values of the dayofweek variable include Monday, Tuesday, Wednesday, Thursday, Friday, Saturday, and Sunday.\n",
    "The total observations for the weekend was 208,800 and for the weekday it was 522,000. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09ec4d63-9de6-4518-8fc2-a305cbc4828a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#part 2\n",
    "#2(a) code\n",
    "\n",
    "dailyvisits_summary = jj_long['dailyvisits'].describe()\n",
    "dailyvisits_median = jj_long['dailyvisits'].median()\n",
    "dailyvisits_mean = jj_long['dailyvisits'].mean()\n",
    "\n",
    "print(dailyvisits_summary)\n",
    "print(\"median: \", dailyvisits_median)\n",
    "print(\"mean\", dailyvisits_mean)\n",
    "\n",
    "zero_dailyvisits = ( jj_long['dailyvisits'] == 0).sum()\n",
    "hundred_dailyvisits = ( jj_long['dailyvisits'] >= 100).sum()\n",
    "thousand_dailyvisits = ( jj_long['dailyvisits'] >= 1000).sum()\n",
    "\n",
    "print(\"zero:\", zero_dailyvisits)\n",
    "print(\"above hundred:\", hundred_dailyvisits)\n",
    "print(\"above thousand:\", thousand_dailyvisits)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89be53e3-877f-46b5-a1e5-d52d3aeddaef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#2(b) code\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.histplot(data = jj_long[jj_long['dailyvisits'] <=100], x ='dailyvisits', bins = 101, edgecolor='blue')\n",
    "plt.xlim(0,100)\n",
    "plt.title(\"Dailyvisits Histogram:Sub-Range(0-100)\")\n",
    "plt.xlabel(\"Number of Dailyvisits\")\n",
    "plt.ylabel(\"count\")\n",
    "\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "083ff31e-3125-4dcd-a0d3-f187bb244454",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.histplot(data = jj_long, x ='dailyvisits', bins = 101, hue='WKND', multiple='dodge', edgecolors='red')\n",
    "plt.xlim(0,100)\n",
    "plt.title(\"Grouped Dailyvisits Histogram:Weekend vs Weekday\")\n",
    "plt.xlabel(\"Number of Dailyvisits\")\n",
    "plt.ylabel(\"count\")\n",
    "plt.legend(labels=['Weekend', 'Weekday'])\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3355e24-dc28-4456-b6b3-c67cb9acee6d",
   "metadata": {},
   "source": [
    "#Question 2 \n",
    "\n",
    "2a: \n",
    "There are a total of 730800 observations. \n",
    "The minimum value is 0.0, the max value is 5915, the median is 3.0, and the mean is 15.39. \n",
    "121,140 observation equal to 0. \n",
    "11229 observations equal to or greater than 100. \n",
    "1403  observations equal to or greater than 1000. \n",
    "\n",
    "2b: \n",
    "I chose the number of bins to be 101 because if I am choosing a range of 0-100 to reduce the skewnewss of the histogram, having 101 bins allows for each individual integer to have its own bin. \n",
    "I chose the sub-range of 100 in order to reduce the overall skewness shown by all the data.\n",
    "\n",
    "2c: \n",
    "Weekdays have a larger proportion of data that falls under the very low dailyvisit range in comparison to Weekends. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d55765ba-013d-440a-8c62-8c6777e9e6c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Part 3 \n",
    "#3(a)\n",
    "\n",
    "sum_per_day = (\n",
    "    jj_long.groupby('dayofweek', as_index=False)['dailyvisits'].sum()\n",
    ")\n",
    "print(sum_per_day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3556f7ff-a08d-4730-a211-0f0ec6a38e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3(b)\n",
    "\n",
    "sum_per_day['dailyvisits'] = pd.to_numeric(sum_per_day['dailyvisits'], errors='coerce')\n",
    "\n",
    "\n",
    "plt.figure(figsize=(8,8))\n",
    "\n",
    "plt.pie(\n",
    "    x= sum_per_day['dailyvisits'],\n",
    "    labels = sum_per_day['dayofweek'], \n",
    "    autopct='%1.1f%%'\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea453fea-8693-4085-99a5-d6725425569b",
   "metadata": {},
   "source": [
    "#Question 3:\n",
    "\n",
    "3(a): The results are shown in the table above. \n",
    "\n",
    "3(b): Pie chart depicting the total dailyvisits across the seven days of the week. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d06280ca-8e97-4e41-8f01-ff71cd4386e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Part 4 \n",
    "#4(a)\n",
    "\n",
    "\n",
    "sum_by_region = (\n",
    "    jj_long.groupby('region', as_index=False)['dailyvisits'].mean()\n",
    ")\n",
    "print(sum_by_region)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e80501c4-6b35-4466-83d6-a10097a27139",
   "metadata": {},
   "outputs": [],
   "source": [
    "#4(b)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15,9), dpi=100)\n",
    "\n",
    "barchart = ax.bar(\n",
    "    x = sum_by_region['region'],\n",
    "    height = sum_by_region['dailyvisits'], \n",
    "    color = 'red'\n",
    "    \n",
    ")\n",
    "ax.set_xlabel(\"region\")\n",
    "ax.set_ylabel(\"mean daily visits\")\n",
    "ax.set_title(\"region based averages\")\n",
    "plt.tight_layout()\n",
    "\n",
    "for bars in barchart:\n",
    "    height= bars.get_height()\n",
    "    ax.text(\n",
    "        bars.get_x() + bars.get_width()/2, \n",
    "        height + 0.1, \n",
    "        f\"{height:.1f}\", \n",
    "        ha = \"center\" , \n",
    "        va = \"bottom\"\n",
    "    )\n",
    "    \n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98e840d7-3b21-4168-b12d-b56397a5ec01",
   "metadata": {},
   "outputs": [],
   "source": [
    "#4(c)\n",
    "\n",
    "jj_long['covid'] = np.where(\n",
    "    jj_long['true_date'] <= pd.to_datetime('2020-03-13'), 'Pre-Covid', 'Post-Covid')\n",
    "\n",
    "region_covid = (\n",
    "    jj_long.groupby(['region', 'covid'], as_index = False)['dailyvisits'].mean())\n",
    "\n",
    "plt.figure(figsize=(15,9))\n",
    "sns.barplot(\n",
    "    data=region_covid, \n",
    "    x = 'region', \n",
    "    y = 'dailyvisits', \n",
    "    hue = 'covid', \n",
    "    palette = 'Dark2')\n",
    "\n",
    "plt.title(\"Pre/Post Covid average's of daily visits by region\")\n",
    "plt.xlabel(\"Region\")\n",
    "plt.ylabel(\"Average Daily Visits\")\n",
    "plt.legend(title = \"Covid Time\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f006888-d749-46d8-9a58-990642df3e5f",
   "metadata": {},
   "source": [
    "#Question 4:\n",
    "\n",
    "4(a): Results are shown in the table above, showing the average dailyvisits by region\n",
    "\n",
    "4(b): Bar chart is visualized in order to show the dailyvisit averages based on the region. \n",
    "\n",
    "4(c): Bar chart is visualized in order to show pre and post covid-19 time period and how the daily averages by region is affected. One difference found between the two sets in the bar chart are that the most regions show a smaller daily average in post covid times in comparison to pre covid times. The second difference is that some regions have a larger drop off from pre covid times to post covid times in comparison to other regions where the drop off was a lot smaller."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a10461d-a972-4501-810b-3292e87b860c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#part 5\n",
    "#5(a)\n",
    "\n",
    "jj_long['year_month'] = jj_long['true_date'].dt.to_period('M')\n",
    "\n",
    "avg_by_month = (\n",
    "    jj_long.groupby('year_month', as_index = False)['dailyvisits'].mean())\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "print(avg_by_month)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef1fad8a-a8f1-488d-8f55-a8377b6d6d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "#5(b)\n",
    "avg_by_month['start_year_month'] = avg_by_month['year_month'].dt.to_timestamp()\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (12,6))\n",
    "ax.plot(\n",
    "    avg_by_month['start_year_month'], \n",
    "    avg_by_month['dailyvisits'], \n",
    "    label = 'Avg Daily Visits')\n",
    "\n",
    "vertical_line = avg_by_month['start_year_month'].dt.year.unique()\n",
    "for year in vertical_line:\n",
    "    new_year = pd.to_datetime(f'{year}-01-01')\n",
    "    ax.axvline(new_year, color = 'black')\n",
    "    \n",
    "march_2020 = pd.to_datetime('2020-03-01')\n",
    "ax.axvline(march_2020, color = 'red', label = 'March 2020')\n",
    "\n",
    "ax.set_title(\"Avg dailyvisits by year-month\")\n",
    "ax.set_xlabel(\"Year-Month\")\n",
    "ax.set_ylabel(\"Avg dailyvisits\")\n",
    "ax.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c1a9837-8a7c-4c92-bfad-12edf7c63b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#5(c)\n",
    "\n",
    "jj_long['year_month'] = jj_long['true_date'].dt.to_period('M')\n",
    "\n",
    "temp = (\n",
    "    jj_long\n",
    "    .groupby('year_month')['dailyvisits']\n",
    "    .agg(['mean','median'])\n",
    "    .reset_index()\n",
    ")\n",
    "temp.rename(columns={'mean':'dailyvisits_mean','median':'dailyvisits_median'}, inplace=True)\n",
    "\n",
    "percentiles_25 = (\n",
    "    jj_long\n",
    "    .groupby('year_month')['dailyvisits']\n",
    "    .apply(lambda x: np.percentile(x, 25))\n",
    "    .reset_index(name='dailyvisits_25th')\n",
    ")\n",
    "\n",
    "percentiles_75 = (\n",
    "    jj_long\n",
    "    .groupby('year_month')['dailyvisits']\n",
    "    .apply(lambda x: np.percentile(x, 75))\n",
    "    .reset_index(name='dailyvisits_75th')\n",
    ")\n",
    "\n",
    "four_dailyvisits = (\n",
    "    temp\n",
    "    .merge(percentiles_25, on='year_month')\n",
    "    .merge(percentiles_75, on='year_month')\n",
    ")\n",
    "\n",
    "\n",
    "four_dailyvisits['start_month'] =four_dailyvisits['year_month'].dt.to_timestamp()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12,6))\n",
    "\n",
    "ax.plot(four_dailyvisits['start_month'], four_dailyvisits['dailyvisits_mean'], label = 'Mean', color='pink')\n",
    "ax.plot(four_dailyvisits['start_month'], four_dailyvisits['dailyvisits_median'], label = 'Median', color='Green')\n",
    "ax.plot(four_dailyvisits['start_month'], four_dailyvisits['dailyvisits_25th'], label = '25th Percentile', color='purple')\n",
    "ax.plot(four_dailyvisits['start_month'], four_dailyvisits['dailyvisits_75th'], label = '75th Percentile', color='Blue')\n",
    "\n",
    "ax.fill_between(\n",
    "    four_dailyvisits['start_month'],\n",
    "    four_dailyvisits['dailyvisits_25th'],\n",
    "    four_dailyvisits['dailyvisits_75th'],\n",
    "    color = 'gray', alpha = 0.2, label = '25th-75th Percentile Range')\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "vertical_line = avg_by_month['start_year_month'].dt.year.unique()\n",
    "for year in vertical_line:\n",
    "    new_year = pd.to_datetime(f'{year}-01-01')\n",
    "    ax.axvline(new_year, color = 'black')\n",
    "    \n",
    "march_2020 = pd.to_datetime('2020-03-01')\n",
    "ax.axvline(march_2020, color = 'red', label = 'March 2020')\n",
    "\n",
    "ax.set_title(\"Dailyvisits by Months - (Mean, Median, 25th, 75th\")\n",
    "ax.set_xlabel(\"year-month\")\n",
    "ax.set_ylabel(\"Dailyvisits\")\n",
    "ax.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69ebfb7e-64bf-4689-8185-40b8bb3fb10b",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "source": [
    "Question 5:\n",
    "\n",
    "5(a): Results shown in table \n",
    "\n",
    "5(b): Line chart displayed shows the average dailyvisits per year-month. \n",
    "\n",
    "5(c): Line chart for the 4 lines is displayed. The pattern for the mean is consitently higher than the 75th percentile, which would mean a right-skewed distribution. At the red line indidicating March 2020, the time covid happened, there was a drop in all measurables indicating the impact Covid-19 had."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46c13cd2-cfc8-4c08-b417-a3855813632d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Part 6: \n",
    "\n",
    "jj_long['year'] = jj_long['true_date'].dt.year\n",
    "\n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "sns.boxplot(\n",
    "    data = jj_long, \n",
    "    x='year',\n",
    "    y='dailyvisits',\n",
    "    color = 'blue'\n",
    ")\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "755a9e66-4463-4062-a2d4-109bfbc8dac2",
   "metadata": {},
   "source": [
    "Question 6: \n",
    "\n",
    "This box plot didn't resemble the normal box and whiskers type of plot. This box plot shows that the majority of the dailyvisits are at a low value, while the outliers are at higher values. \n",
    "\n",
    "In regards to the line plot from the previous question, this plot also exemplifies that there was a skewness in the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fca38c0-da41-4d94-83f8-3f47f4132ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Part 7 \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    " \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "us_state = (\n",
    "    jj_long\n",
    "    .groupby('region', as_index=False)['dailyvisits']\n",
    "    .mean()\n",
    ")\n",
    "\n",
    "state_id = {\n",
    "    'AL': '01', 'AK': '02', 'AZ': '04', 'AR': '05', 'CA': '06',\n",
    "    'CO': '08', 'CT': '09', 'DE': '10', 'FL': '12', 'GA': '13',\n",
    "    'HI': '15', 'ID': '16', 'IL': '17', 'IN': '18', 'IA': '19',\n",
    "    'KS': '20', 'KY': '21', 'LA': '22', 'ME': '23', 'MD': '24',\n",
    "    'MA': '25', 'MI': '26', 'MN': '27', 'MS': '28', 'MO': '29',\n",
    "    'MT': '30', 'NE': '31', 'NV': '32', 'NH': '33', 'NJ': '34',\n",
    "    'NM': '35', 'NY': '36', 'NC': '37', 'ND': '38', 'OH': '39',\n",
    "    'OK': '40', 'OR': '41', 'PA': '42', 'RI': '44', 'SC': '45',\n",
    "    'SD': '46', 'TN': '47', 'TX': '48', 'UT': '49', 'VT': '50',\n",
    "    'VA': '51', 'WA': '53', 'WV': '54', 'WI': '55', 'WY': '56',\n",
    "    'DC': '11'\n",
    "}\n",
    "\n",
    "us_state['state_code'] = us_state['region'].map(state_id)\n",
    "\n",
    "\n",
    "\n",
    "url_states = \"https://raw.githubusercontent.com/python-visualization/folium/master/examples/data/us-states.json\"\n",
    "geoData = gpd.read_file(url_states)\n",
    "\n",
    "\n",
    "\n",
    "combined_data = pd.merge(\n",
    "    geoData, \n",
    "    us_state, \n",
    "    left_on =\"id\",\n",
    "    right_on =\"region\", \n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12,8))\n",
    "\n",
    "combined_data.plot(\n",
    "    column = 'dailyvisits',\n",
    "    legend = True, \n",
    "    ax =ax)\n",
    "\n",
    "ax.set_title(\"State by State dailyvisits\")\n",
    "ax.set_axis_off()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d10eb327-53f3-4a5f-850d-bb749514a5da",
   "metadata": {},
   "source": [
    "Question 7: \n",
    "\n",
    "(a) Based on a smell test based on public information, Nevada is the state with the highest average daily customers and according to the map the state of Nevada is highlighted yellow showing they have the highest average daily customers. \n",
    "\n",
    "(b)From this geographic visualization I learned that for some reason Nevada is obsessed with Jimmy John's. Most of the states range in the dark blue to purple range indidcating a lower average of daily customers. The states that are really purple could indicate the lack of presence of Jimmy John's in those state. \n",
    "\n",
    "(c)A business owner would look at this map and would see that the states that already have the ball rolling but not the highest averages could benfit from the implementation of an expansion of the business in those areas. Incorporating further marketing in these areas may drive their profits even higher as they are expanding their fan base(customers). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc70933d-fc7f-4d68-b62e-68adf3558883",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
